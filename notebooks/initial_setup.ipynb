{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "\n",
    "# Workflow for AI Quiz Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Setup Output Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_output_structure(pdf_name, display_path=False):\n",
    "    \"\"\"\n",
    "    Create the output folder structure for a given PDF as follows:\n",
    "    ./outputs/<pdf_name>/\n",
    "        - raw_text.txt\n",
    "        - chunks.json\n",
    "        - questions.json\n",
    "        - run_metadata.json\n",
    "    \"\"\"\n",
    "    base_output = Path(\"./outputs\") / pdf_name\n",
    "    base_output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    raw_text_file = base_output / \"raw_text.txt\"\n",
    "    \n",
    "    output_paths = {\n",
    "        \"base\": base_output,\n",
    "        \"raw_text\": raw_text_file,\n",
    "        \"chunks_json\": base_output / \"chunks.json\",\n",
    "        \"questions_json\": base_output / \"questions.json\",\n",
    "        \"metadata_json\": base_output / \"run_metadata.json\"\n",
    "    }\n",
    "\n",
    "    if display_path:\n",
    "        print(f\"\\nOutput structure will be created as follows: {output_paths['base']}\")\n",
    "        print(f\"  - raw_text.txt: {output_paths['raw_text']}\")\n",
    "        print(f\"  - chunks.json: {output_paths['chunks_json']}\")\n",
    "        print(f\"  - questions.json: {output_paths['questions_json']}\")\n",
    "        print(f\"  - run_metadata.json: {output_paths['metadata_json']}\")\n",
    "        print('\\n')\n",
    "    \n",
    "    return output_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Extract PDF Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path, output_paths, return_pages=False, save_pages=False):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file.\n",
    "    \"\"\"\n",
    "    \n",
    "    pdf_path = Path(pdf_path)\n",
    "    if not pdf_path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {pdf_path}\")\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_text = []\n",
    "    for page in doc:\n",
    "        text = page.get_text(\"text\")\n",
    "        pages_text.append(text)\n",
    "    doc.close()\n",
    "\n",
    "    # Save extracted text to raw_text.txt\n",
    "    if save_pages:\n",
    "        raw_text_file = output_paths[\"raw_text\"]\n",
    "        with open(raw_text_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\\n\".join(pages_text))\n",
    "        print(f\"Saved extracted_text.txt to {raw_text_file}\")\n",
    "\n",
    "    if return_pages:\n",
    "        return pages_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Cleaning the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Minimal cleaning for PDF-extracted text.\n",
    "\n",
    "    What this does:\n",
    "    1. Unicode normalization (fixes ligatures like ﬁ, ﬀ, etc.)\n",
    "    2. Normalize newlines and whitespace\n",
    "    3. Remove standalone page numbers (e.g., '15', '203')\n",
    "\n",
    "    What this intentionally does NOT do (may implement later):\n",
    "    - No header/footer detection\n",
    "    - No paragraph restructuring\n",
    "    - No figure/table removal\n",
    "    - No heuristic guessing\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Unicode normalization (fix ligatures and weird characters)\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "    # 2. Normalize newlines\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    # 3. Normalize whitespace (keep line structure)\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = \"\\n\".join(line.rstrip() for line in text.split(\"\\n\"))\n",
    "\n",
    "    # 4. Remove standalone page numbers\n",
    "    cleaned_lines = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        stripped = line.strip()\n",
    "        if stripped.isdigit() and len(stripped) <= 4:\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "\n",
    "    # 5. Collapse excessive blank lines (keep max 1)\n",
    "    cleaned_text = \"\\n\".join(cleaned_lines)\n",
    "    cleaned_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", cleaned_text)\n",
    "\n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Chunking Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_fixed_size(text, output_paths, chunk_size = 4000, overlap= 400, min_chunk_size = 800, save_pages=False):\n",
    "    \"\"\"\n",
    "    Splits text into fixed-size character chunks with overlap.\n",
    "\n",
    "    Returns:\n",
    "      List of chunks:\n",
    "      {\n",
    "        \"chunk_id\": int,\n",
    "        \"text\": str,\n",
    "        \"char_len\": int\n",
    "      }\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    text_len = len(text)\n",
    "    chunk_id = 0\n",
    "    start = 0\n",
    "\n",
    "    while start < text_len:\n",
    "        end = start + chunk_size\n",
    "        chunk_text = text[start:end].strip()\n",
    "\n",
    "        if len(chunk_text) >= min_chunk_size:\n",
    "            chunks.append({\n",
    "                \"chunk_id\": chunk_id,\n",
    "                \"text\": chunk_text,\n",
    "                \"char_len\": len(chunk_text)\n",
    "            })\n",
    "            chunk_id += 1\n",
    "\n",
    "        # move start forward, keeping overlap\n",
    "        start += max(1, chunk_size - overlap)\n",
    "\n",
    "    # Save chunks to JSON\n",
    "    if save_pages:\n",
    "        chunks_file = output_paths[\"chunks_json\"]\n",
    "        with open(chunks_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(chunks, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Saved chunks to {chunks_file}\")\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Generate Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Simpler Promt for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_prompt(chunk_text, n_questions = 2):\n",
    "    return f\"\"\"\n",
    "Generate {n_questions} quiz questions from the following text.\n",
    "Ignore formatting artifacts from PDFs such as page numbers, figure labels,\n",
    "axis ticks, or broken line wraps.\n",
    "\n",
    "Generate {n_questions} total questions and return them in the following format:\n",
    "    {{\n",
    "        questions:[\n",
    "            {{\n",
    "                question_id: 1,\n",
    "                question: question_text,\n",
    "                options: ['A', 'B', 'C', 'D']\n",
    "                correct_answer: 'A'\n",
    "            }},\n",
    "\n",
    "            {{\n",
    "                question_id: 2,\n",
    "                question: question_text,\n",
    "                options: ['A', 'B', 'C', 'D']\n",
    "                correct_answer: 'C'\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "Text:\n",
    "\\\"\\\"\\\"\\n{chunk_text}\\n\\\"\\\"\\\"\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(client, prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You generate clear quiz questions from textbook content.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.4,\n",
    "        max_tokens=600\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions_simple(chunks, questions_per_chunk = 2, max_chunks= 5):\n",
    "    results = []\n",
    "    client = OpenAI()\n",
    "\n",
    "    for chunk in chunks[:max_chunks]:\n",
    "        prompt = build_simple_prompt(\n",
    "            chunk[\"text\"],\n",
    "            n_questions=questions_per_chunk\n",
    "        )\n",
    "        response = call_llm(client, prompt)\n",
    "\n",
    "        results.append({\n",
    "            \"chunk_id\": chunk[\"chunk_id\"],\n",
    "            \"questions_text\": response\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Main Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "##### Generate Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_question_prompt(chunk_text, num_questions=10):\n",
    "    '''\n",
    "    Generate a prompt for creating quiz questions from a text chunk.\n",
    "    '''\n",
    "    \n",
    "    return f\"\"\"\n",
    "    You are an expert at creating quiz questions that test deep understanding of the material. \n",
    "Generate {num_questions} challenging quiz questions of medium difficulty based on the following except. \n",
    "The excerpt may contain PDF artifacts (page numbers, figure labels, axis ticks, glossary/margin terms, broken line wraps).\n",
    "Ignore non-explanatory artifacts and focus on the conceptual content. \n",
    "\n",
    "Each question should have 4 answer options (A, B, C, D) with only one correct answer. \n",
    "The questions should require critical thinking and not be answerable by simple keyword matching.\n",
    "\n",
    "Generate {num_questions} total questions and return them in the following format:\n",
    "{{\n",
    "    \"questions\":[\n",
    "        {{\n",
    "            \"type\": \"mcq\",\n",
    "            \"question_id\": 1,\n",
    "            \"question\": \"What is the main topic of this excerpt?\",\n",
    "            \"choices\": [\"A\", \"B\", \"C\", \"D\"],\n",
    "            \"answer_index\": 0\n",
    "        }},\n",
    "\n",
    "        {{\n",
    "            \"type\": \"mcq\",\n",
    "            \"question_id\": 2,\n",
    "            \"question\": \"What is the main topic of this excerpt?\",\n",
    "            \"choices\": [\"A\", \"B\", \"C\", \"D\"],\n",
    "            \"answer_index\": 2\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- choices must be exactly 4 items\n",
    "- answer_index must be an integer 0..3\n",
    "- questions must be answerable from the given text (no outside knowledge)\n",
    "- avoid trivial questions (e.g., “What is the chapter number?”)\n",
    "\n",
    "Excerpt: \n",
    "\\\"\\\"\\\"\\n{chunk_text}\\n\\\"\\\"\\\"\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Potential improvements to consider:\n",
    "- Add difficulty option later\n",
    "- Add a questions validation function later on, to validate questions and answer format generated by LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai_text(client, prompt, model = \"gpt-4.1-mini\"):\n",
    "    \"\"\"\n",
    "    Call the OpenAI API with a text prompt and return the response text\n",
    "    \"\"\"\n",
    "    resp = client.responses.create(\n",
    "        model=model,\n",
    "        input=prompt,\n",
    "        temperature=0.3,\n",
    "        max_output_tokens=900,\n",
    "    )\n",
    "    return resp.output_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "##### Validate generated JSON Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_json_loads(text):\n",
    "    \"\"\"\n",
    "    Ensure result is a JSON object otherwise return first {...} block it can find\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        start = text.find(\"{\")\n",
    "        end = text.rfind(\"}\")\n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            return json.loads(text[start:end + 1])\n",
    "        raise\n",
    "\n",
    "def validate_json(q):\n",
    "    question_type = q.get(\"type\")\n",
    "    if question_type != \"mcq\":\n",
    "        return \"type must be 'mcq'\"\n",
    "\n",
    "    question = q.get(\"question\")\n",
    "    if not isinstance(question, str) or not question.strip():\n",
    "        return \"missing/invalid question\"\n",
    "\n",
    "    choices = q.get(\"choices\")\n",
    "    if not isinstance(choices, list) or len(choices) != 4 or not all(isinstance(c, str) and c.strip() for c in choices):\n",
    "        return \"choices must be a list of exactly 4 non-empty strings\"\n",
    "\n",
    "    answer = q.get(\"answer_index\")\n",
    "    if not isinstance(answer, int) or not (0 <= answer <= 3):\n",
    "        return \"answer_index must be an int in [0..3]\"\n",
    "\n",
    "    # Optional explanation\n",
    "    if \"explanation\" in q and q[\"explanation\"] is not None and not isinstance(q[\"explanation\"], str):\n",
    "        return \"explanation must be a string if present\"\n",
    "\n",
    "    # Light anti-noise check (optional but helpful)\n",
    "    bad_markers = [\"doi.org\", \"©\", \"springer\", \"page \"]\n",
    "    low_q = question.lower()\n",
    "    if any(m in low_q for m in bad_markers):\n",
    "        return \"question looks like it used PDF boilerplate\"\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mcqs_over_chunks(chunks, pdf_name, output_paths, model = \"gpt-4.1-mini\", mcqs_per_chunk = 2, max_chunks = None):\n",
    "    \"\"\"\n",
    "    Reads the chunks, generates MCQs, validates them, and saves them\n",
    "    \"\"\"\n",
    "\n",
    "    run_ts = datetime.now().astimezone().isoformat(timespec=\"seconds\")\n",
    "\n",
    "    questions_file = output_paths[\"questions_json\"]\n",
    "    metadata_file = output_paths[\"metadata_json\"]\n",
    "\n",
    "    subset = chunks if max_chunks is None else chunks[:max_chunks]\n",
    "\n",
    "    # Maintain list of valid and invalid questions/results\n",
    "    all_valid = []\n",
    "    all_invalid = []\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    for i, chunk in enumerate(subset, 1):\n",
    "        prompt = build_question_prompt(chunk[\"text\"], num_questions=mcqs_per_chunk)\n",
    "\n",
    "        try:\n",
    "            raw = call_openai_text(client, prompt, model=model)\n",
    "            data = safe_json_loads(raw)\n",
    "            qs = data.get(\"questions\", [])\n",
    "\n",
    "            if not isinstance(qs, list) or len(qs) != mcqs_per_chunk:\n",
    "                raise ValueError(f\"Expected {mcqs_per_chunk} questions, got {len(qs) if isinstance(qs, list) else 'non-list'}\")\n",
    "\n",
    "            for q in qs:\n",
    "                if not isinstance(q, dict):\n",
    "                    all_invalid.append({\n",
    "                        \"chunk_id\": chunk[\"chunk_id\"],\n",
    "                        \"error\": \"question is not an object\",\n",
    "                        \"raw_value\": q\n",
    "                    })\n",
    "                    continue\n",
    "\n",
    "                err = validate_json(q)\n",
    "                if err:\n",
    "                    all_invalid.append({\n",
    "                        \"chunk_id\": chunk[\"chunk_id\"],\n",
    "                        \"error\": err,\n",
    "                        \"raw_value\": q\n",
    "                    })\n",
    "                    continue\n",
    "\n",
    "                q_out = dict(q)\n",
    "                q_out[\"question_id\"] = str(uuid.uuid4())\n",
    "                q_out[\"chunk_id\"] = chunk[\"chunk_id\"]\n",
    "                # convenience field\n",
    "                q_out[\"answer\"] = q_out[\"choices\"][q_out[\"answer_index\"]]\n",
    "                all_valid.append(q_out)\n",
    "\n",
    "            print(f\"[{i}/{len(subset)}] chunk_id={chunk['chunk_id']} ✓ valid so far={len(all_valid)} invalid so far={len(all_invalid)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            all_invalid.append({\n",
    "                \"chunk_id\": chunk[\"chunk_id\"],\n",
    "                \"error\": f\"generation/parsing failed: {e}\",\n",
    "                \"raw_value\": None\n",
    "            })\n",
    "            print(f\"[{i}/{len(subset)}] chunk_id={chunk['chunk_id']} ✗ failed: {e}\")\n",
    "\n",
    "    # Write questions.json\n",
    "    with open(questions_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_valid, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # Write run_metadata.json (repro + debugging)\n",
    "    metadata = {\n",
    "        \"pdf_name\": pdf_name,\n",
    "        \"timestamp\": run_ts,\n",
    "        \"inputs\": {\n",
    "            \"num_chunks_available\": len(chunks),\n",
    "            \"num_chunks_processed\": len(subset),\n",
    "        },\n",
    "        \"chunk_schema\": {\n",
    "            \"fields\": [\"chunk_id\", \"text\", \"char_len\"]\n",
    "        },\n",
    "        \"generation\": {\n",
    "            \"model\": model,\n",
    "            \"mcqs_per_chunk\": mcqs_per_chunk,\n",
    "            \"temperature\": 0.3,\n",
    "            \"max_output_tokens\": 900\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"questions_path\": str(questions_file),\n",
    "            \"metadata_path\": str(metadata_file),\n",
    "        },\n",
    "        \"results\": {\n",
    "            \"valid_questions\": len(all_valid),\n",
    "            \"invalid_items\": len(all_invalid),\n",
    "        },\n",
    "        # Keep some invalid samples for debugging without bloating file\n",
    "        \"invalid_samples\": all_invalid[:10],\n",
    "    }\n",
    "\n",
    "    with open(metadata_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return {\n",
    "        \"questions_path\": str(questions_file),\n",
    "        \"metadata_path\": str(metadata_file),\n",
    "        \"valid_questions\": all_valid,\n",
    "        \"invalid_items\": all_invalid,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Main Execution Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_file = Path(\"test_pdfs/islr_chap_2.pdf\")\n",
    "pdf_file = Path(\"test_pdfs/multi_column_research_paper.pdf\")\n",
    "pdf_name = pdf_file.stem.lower().replace(' ', '_')  # Get filename without extension\n",
    "\n",
    "if pdf_file.exists():\n",
    "    # Setup output structure\n",
    "    output_paths = setup_output_structure(pdf_name, display_path=True)\n",
    "    \n",
    "    # Extract text from PDF\n",
    "    pages = extract_text_from_pdf(pdf_file, output_paths, return_pages=True, save_pages=True)\n",
    "    text_pages = \"\\n\\n\".join(pages)\n",
    "\n",
    "    # print(f\"Extracted {len(pages_text)} pages\")\n",
    "    # print(\"--- Page 1 preview ---\")\n",
    "    # print(pages_text[0][:500])\n",
    "    \n",
    "    # Text cleaning\n",
    "    text_cleaned = clean_text(text_pages)\n",
    "    # print('\\n' + text_cleaned[:1500])\n",
    "\n",
    "    # Text chunking\n",
    "    text_chunked = chunk_fixed_size(\n",
    "                            text_cleaned,\n",
    "                            output_paths,\n",
    "                            chunk_size=4000,\n",
    "                            overlap=400,\n",
    "                            min_chunk_size=800,\n",
    "                            save_pages=True                            \n",
    "                        )\n",
    "    # print(f\"Created {len(text_chunked)} chunks\")\n",
    "\n",
    "    # Generate Questions\n",
    "\n",
    "    # Simple initial model\n",
    "    # num_questions = 10\n",
    "    # results = generate_questions_simple(text_chunked, questions_per_chunk=5, max_chunks=5)\n",
    "\n",
    "    # print(results[0][\"questions_text\"])\n",
    "\n",
    "    # More advanced prompt + validation\n",
    "    result = generate_mcqs_over_chunks(\n",
    "        text_chunked,\n",
    "        pdf_name,\n",
    "        output_paths,\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        mcqs_per_chunk=2,\n",
    "        max_chunks=4,  # keep small while testing cost/quality\n",
    "    )\n",
    "\n",
    "    print(result[\"questions_path\"])\n",
    "    print(result[\"metadata_path\"])\n",
    "    print(\"valid:\", len(result[\"valid_questions\"]), \"invalid:\", len(result[\"invalid_items\"]))\n",
    "\n",
    "\n",
    "else:\n",
    "    print(f\"Please place your PDF at: {pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['valid_questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['invalid_items']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Quiz_Generator-w9UIxfSy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
